{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDswiB5tP6DV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tciQlHXVQiLx",
        "outputId": "5af0a2d6-8060-4c4c-f604-ac5b8197341f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the datasets and scaling the continuous features"
      ],
      "metadata": {
        "id": "cSkqZg6lHI9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_raw = pd.read_csv('/content/drive/MyDrive/Satellite_Property_Project/train_processed.csv')\n",
        "test_df_raw = pd.read_csv('/content/drive/MyDrive/Satellite_Property_Project/test_processed.csv')\n",
        "\n",
        "continuous_features = [\n",
        "    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
        "    'floors', 'sqft_basement', 'lat', 'long',\n",
        "    'sqft_living15', 'sqft_lot15', 'house_age',\n",
        "    'grade', 'condition', 'view'\n",
        "]\n",
        "\n",
        "binary_features = ['is_renovated', 'waterfront']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_df, val_df = train_test_split(train_df_raw, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler.fit(train_df[continuous_features])\n",
        "\n",
        "train_df[continuous_features] = scaler.transform(train_df[continuous_features])\n",
        "val_df[continuous_features] = scaler.transform(val_df[continuous_features])\n",
        "test_df_raw[continuous_features] = scaler.transform(test_df_raw[continuous_features])\n",
        "\n",
        "all_features = continuous_features + binary_features"
      ],
      "metadata": {
        "id": "XEBYFJGxQk3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing dataset for training"
      ],
      "metadata": {
        "id": "YnutalZRHPjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, dataframe, cols, is_test=False):\n",
        "        self.df = dataframe\n",
        "        self.cols = cols\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        tabular = torch.tensor(row[self.cols].values.astype(np.float32))\n",
        "\n",
        "        if self.is_test:\n",
        "            return tabular, row['id']\n",
        "        else:\n",
        "            label = torch.tensor(row['log_price'], dtype=torch.float32)\n",
        "            return tabular, label\n",
        "\n",
        "batch_size = 64\n",
        "train_ds = TabularDataset(train_df, all_features)\n",
        "val_ds = TabularDataset(val_df, all_features)\n",
        "test_ds = TabularDataset(test_df_raw, all_features, is_test=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Tabular Data Loaded Successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5kYGqAvQnCt",
        "outputId": "c4869441-aa9e-495a-8544-3c29aa092caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabular Data Loaded Successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecturing a simple neural network"
      ],
      "metadata": {
        "id": "cuz3ykB5HT1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleTabularNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleTabularNN, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x.squeeze(1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleTabularNN(input_dim=len(all_features)).to(device)\n",
        "print(f\"Model initialized on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6rpHIEVQoxi",
        "outputId": "14aa1a7c-21c3-477e-fad9-400710e1e664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model for 200 epochs implemented with early stopping"
      ],
      "metadata": {
        "id": "vcNy901ZHdM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/MainProject/Models/best_simple_tabular_nn.pth\"\n",
        "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "def train_simple_with_early_stopping(\n",
        "    num_epochs=200,\n",
        "    patience=15,\n",
        "    min_delta=1e-4\n",
        "):\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for tabular, labels in train_loader:\n",
        "            tabular = tabular.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(tabular)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for tabular, labels in val_loader:\n",
        "                tabular = tabular.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(tabular)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1:03d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if best_val_loss - val_loss > min_delta:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), SAVE_PATH)\n",
        "            print(\"  âœ“ Saved new best model\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  âœ— No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(\"\\nðŸ›‘ Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    print(\"\\nTraining completed.\")\n",
        "\n",
        "train_simple_with_early_stopping(\n",
        "    num_epochs=200,\n",
        "    patience=15\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwbubhbTQpiB",
        "outputId": "c4a5aeac-49a1-44e3-d90e-f8ce1b202955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train Loss: 0.9188 | Val Loss: 0.2373\n",
            "  âœ“ Saved new best model\n",
            "Epoch 002 | Train Loss: 0.6175 | Val Loss: 0.1356\n",
            "  âœ“ Saved new best model\n",
            "Epoch 003 | Train Loss: 0.4195 | Val Loss: 0.0689\n",
            "  âœ“ Saved new best model\n",
            "Epoch 004 | Train Loss: 0.3384 | Val Loss: 0.0760\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 005 | Train Loss: 0.2280 | Val Loss: 0.0640\n",
            "  âœ“ Saved new best model\n",
            "Epoch 006 | Train Loss: 0.1786 | Val Loss: 0.1051\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 007 | Train Loss: 0.1139 | Val Loss: 0.0596\n",
            "  âœ“ Saved new best model\n",
            "Epoch 008 | Train Loss: 0.0916 | Val Loss: 0.0448\n",
            "  âœ“ Saved new best model\n",
            "Epoch 009 | Train Loss: 0.0706 | Val Loss: 0.0452\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 010 | Train Loss: 0.0687 | Val Loss: 0.0442\n",
            "  âœ“ Saved new best model\n",
            "Epoch 011 | Train Loss: 0.0634 | Val Loss: 0.0580\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 012 | Train Loss: 0.0649 | Val Loss: 0.0886\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 013 | Train Loss: 0.0662 | Val Loss: 0.0628\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 014 | Train Loss: 0.0565 | Val Loss: 0.0789\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 015 | Train Loss: 0.0568 | Val Loss: 0.0584\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 016 | Train Loss: 0.0544 | Val Loss: 0.0873\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 017 | Train Loss: 0.0614 | Val Loss: 0.0810\n",
            "  âœ— No improvement (7/15)\n",
            "Epoch 018 | Train Loss: 0.0577 | Val Loss: 0.0451\n",
            "  âœ— No improvement (8/15)\n",
            "Epoch 019 | Train Loss: 0.0526 | Val Loss: 0.0547\n",
            "  âœ— No improvement (9/15)\n",
            "Epoch 020 | Train Loss: 0.0516 | Val Loss: 0.0644\n",
            "  âœ— No improvement (10/15)\n",
            "Epoch 021 | Train Loss: 0.0560 | Val Loss: 0.0431\n",
            "  âœ“ Saved new best model\n",
            "Epoch 022 | Train Loss: 0.0547 | Val Loss: 0.0480\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 023 | Train Loss: 0.0534 | Val Loss: 0.0488\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 024 | Train Loss: 0.0490 | Val Loss: 0.0484\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 025 | Train Loss: 0.0562 | Val Loss: 0.0556\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 026 | Train Loss: 0.0500 | Val Loss: 0.0558\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 027 | Train Loss: 0.0505 | Val Loss: 0.0469\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 028 | Train Loss: 0.0483 | Val Loss: 0.0415\n",
            "  âœ“ Saved new best model\n",
            "Epoch 029 | Train Loss: 0.0472 | Val Loss: 0.0401\n",
            "  âœ“ Saved new best model\n",
            "Epoch 030 | Train Loss: 0.0470 | Val Loss: 0.0395\n",
            "  âœ“ Saved new best model\n",
            "Epoch 031 | Train Loss: 0.0440 | Val Loss: 0.0409\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 032 | Train Loss: 0.0491 | Val Loss: 0.0446\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 033 | Train Loss: 0.0476 | Val Loss: 0.0448\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 034 | Train Loss: 0.0464 | Val Loss: 0.0402\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 035 | Train Loss: 0.0460 | Val Loss: 0.0397\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 036 | Train Loss: 0.0457 | Val Loss: 0.0501\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 037 | Train Loss: 0.0492 | Val Loss: 0.0453\n",
            "  âœ— No improvement (7/15)\n",
            "Epoch 038 | Train Loss: 0.0507 | Val Loss: 0.0789\n",
            "  âœ— No improvement (8/15)\n",
            "Epoch 039 | Train Loss: 0.0484 | Val Loss: 0.0610\n",
            "  âœ— No improvement (9/15)\n",
            "Epoch 040 | Train Loss: 0.0488 | Val Loss: 0.0570\n",
            "  âœ— No improvement (10/15)\n",
            "Epoch 041 | Train Loss: 0.0459 | Val Loss: 0.0445\n",
            "  âœ— No improvement (11/15)\n",
            "Epoch 042 | Train Loss: 0.0453 | Val Loss: 0.0404\n",
            "  âœ— No improvement (12/15)\n",
            "Epoch 043 | Train Loss: 0.0470 | Val Loss: 0.0385\n",
            "  âœ“ Saved new best model\n",
            "Epoch 044 | Train Loss: 0.0489 | Val Loss: 0.0690\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 045 | Train Loss: 0.0547 | Val Loss: 0.0431\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 046 | Train Loss: 0.0660 | Val Loss: 0.0538\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 047 | Train Loss: 0.0546 | Val Loss: 0.0401\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 048 | Train Loss: 0.0661 | Val Loss: 0.0458\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 049 | Train Loss: 0.0509 | Val Loss: 0.0512\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 050 | Train Loss: 0.0487 | Val Loss: 0.0370\n",
            "  âœ“ Saved new best model\n",
            "Epoch 051 | Train Loss: 0.0530 | Val Loss: 0.0425\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 052 | Train Loss: 0.0593 | Val Loss: 0.0370\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 053 | Train Loss: 0.0510 | Val Loss: 0.0454\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 054 | Train Loss: 0.0668 | Val Loss: 0.0402\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 055 | Train Loss: 0.0503 | Val Loss: 0.0396\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 056 | Train Loss: 0.0485 | Val Loss: 0.0383\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 057 | Train Loss: 0.0505 | Val Loss: 0.0362\n",
            "  âœ“ Saved new best model\n",
            "Epoch 058 | Train Loss: 0.0454 | Val Loss: 0.0422\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 059 | Train Loss: 0.0432 | Val Loss: 0.0400\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 060 | Train Loss: 0.0442 | Val Loss: 0.0440\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 061 | Train Loss: 0.0440 | Val Loss: 0.0354\n",
            "  âœ“ Saved new best model\n",
            "Epoch 062 | Train Loss: 0.0442 | Val Loss: 0.0463\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 063 | Train Loss: 0.0430 | Val Loss: 0.0353\n",
            "  âœ“ Saved new best model\n",
            "Epoch 064 | Train Loss: 0.0450 | Val Loss: 0.0427\n",
            "  âœ— No improvement (1/15)\n",
            "Epoch 065 | Train Loss: 0.0465 | Val Loss: 0.0357\n",
            "  âœ— No improvement (2/15)\n",
            "Epoch 066 | Train Loss: 0.0431 | Val Loss: 0.0415\n",
            "  âœ— No improvement (3/15)\n",
            "Epoch 067 | Train Loss: 0.0448 | Val Loss: 0.0429\n",
            "  âœ— No improvement (4/15)\n",
            "Epoch 068 | Train Loss: 0.0478 | Val Loss: 0.0412\n",
            "  âœ— No improvement (5/15)\n",
            "Epoch 069 | Train Loss: 0.0437 | Val Loss: 0.0366\n",
            "  âœ— No improvement (6/15)\n",
            "Epoch 070 | Train Loss: 0.0438 | Val Loss: 0.0407\n",
            "  âœ— No improvement (7/15)\n",
            "Epoch 071 | Train Loss: 0.0409 | Val Loss: 0.0384\n",
            "  âœ— No improvement (8/15)\n",
            "Epoch 072 | Train Loss: 0.0445 | Val Loss: 0.0594\n",
            "  âœ— No improvement (9/15)\n",
            "Epoch 073 | Train Loss: 0.0439 | Val Loss: 0.0464\n",
            "  âœ— No improvement (10/15)\n",
            "Epoch 074 | Train Loss: 0.0447 | Val Loss: 0.0595\n",
            "  âœ— No improvement (11/15)\n",
            "Epoch 075 | Train Loss: 0.0440 | Val Loss: 0.0398\n",
            "  âœ— No improvement (12/15)\n",
            "Epoch 076 | Train Loss: 0.0418 | Val Loss: 0.0411\n",
            "  âœ— No improvement (13/15)\n",
            "Epoch 077 | Train Loss: 0.0473 | Val Loss: 0.0438\n",
            "  âœ— No improvement (14/15)\n",
            "Epoch 078 | Train Loss: 0.0443 | Val Loss: 0.0412\n",
            "  âœ— No improvement (15/15)\n",
            "\n",
            "ðŸ›‘ Early stopping triggered\n",
            "\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating RMSE and R2 values"
      ],
      "metadata": {
        "id": "SdQ1XujHHinr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH))\n",
        "model.eval()\n",
        "\n",
        "val_preds, val_targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for tabular, labels in val_loader:\n",
        "        tabular, labels = tabular.to(device), labels.to(device)\n",
        "        out = model(tabular)\n",
        "        val_preds.extend(out.cpu().numpy().flatten())\n",
        "        val_targets.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "y_true = np.expm1(val_targets)\n",
        "y_pred = np.expm1(val_preds)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(f\"TABULAR ONLY RESULTS:\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "print(f\"RMSE:     ${rmse:,.2f}\")\n",
        "print(\"----------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT25V6w-QsbD",
        "outputId": "aa4db3ec-7c69-4511-b45a-52369f813c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "TABULAR ONLY RESULTS:\n",
            "R2 Score: 0.8500\n",
            "RMSE:     $136,789.82\n",
            "----------------------------\n"
          ]
        }
      ]
    }
  ]
}